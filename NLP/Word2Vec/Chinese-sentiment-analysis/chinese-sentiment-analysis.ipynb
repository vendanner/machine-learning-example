{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入所需的库\n",
    "我们依旧会用gensim去做word2vec的处理，会用sklearn当中的SVM进行建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 2015.12.09\n",
    "\n",
    "@author: Hanxiaoyang\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "import sys  \n",
    "import os\n",
    "# reload(sys)  \n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "os.mkdir(\"svm_data/svm_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据，做预处理(分词)，切分训练集与测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_and_preprocessing():\n",
    "    neg=pd.read_excel('data/neg.xls',header=None,index=None)\n",
    "    pos=pd.read_excel('data/pos.xls',header=None,index=None)\n",
    "    \n",
    "    # jieba 库 对句子分词\n",
    "    # 这里是创建匿名函数并把函数地址赋值给 cw\n",
    "    cw = lambda x: list(jieba.cut(x))\n",
    "    pos['words'] = pos[0].apply(cw)\n",
    "    neg['words'] = neg[0].apply(cw)\n",
    "    \n",
    "    #print pos['words']\n",
    "    #use 1 for positive sentiment, 0 for negative\n",
    "    # 自行健 label ，pos = 1，neg = 0\n",
    "    # concatenate 是组合，np.ones + np.zeros\n",
    "    y = np.concatenate((np.ones(len(pos)), np.zeros(len(neg))))\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(np.concatenate((pos['words'], neg['words'])), y, test_size=0.2)\n",
    "    \n",
    "#     np.save('svm_data/y_train.npy',y_train)\n",
    "#     np.save('svm_data/y_test.npy',y_test)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集查看\n",
      "['来电', '的', '反应', '很', '慢', '，', '都', '要', '等', '好长时间', '才', '通', '，', '怀疑', '它', '信号', '不好', '，', '果然', '，', '它', '的', '信号', '在', '翻盖', '，', '合盖', '或者', '刚', '挂断', '电话', '时', '居然', '经常', '从', '五格', '变到', '两到', '三格', '，', '有时', '甚至', '变为', '一', '格', '，', '而且', '对', '来电', '反应', '很', '慢', '，', '很', '长时间', '才能', '通', '。'] 0.0\n",
      "['本书', '一', '开始', '附带', '了', '大量', '的', '历史', '知识', '，', '看', '的', '我', '很', '不耐烦', '，', '觉得', '也', '没', '组织', '好', '头绪', '，', '很乱', '的', '感觉', '，', '但是', '似乎', '大家', '对', '这', '本书', '评价', '还', '不错', '，', '那么', '耐着', '性子', '看', '下去', '，', '从', '第三本', '开始', '，', '真的', '发现', '渐入佳境', '，', '作者', '开始', '找到', '感觉', 'le', '事情', '的', '进展', '开始', '有', '那么些', '意思', '了', '，', '最后', '一口气', '看', '完全', '部五本', '，', '发现', '喜欢', '上', '了', '这', '套书', '，', '看来', '还要', '继续', '追下去', '，', '只是', '可惜', '还', '没出', '完', '，', '真', '希望', '看到', '后面', '，', '不', '知道', '作者', '会', '给', '我们', '怎样', '的', '结果', '？'] 0.0\n"
     ]
    }
   ],
   "source": [
    "# 拆分好测试和验证集\n",
    "x_train, x_test, y_train, y_test = load_file_and_preprocessing()\n",
    "print(\"数据集查看\")\n",
    "print(x_train[5],y_train[5])\n",
    "print(x_train[6],y_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对每个句子的所有词向量取均值，来生成一个句子的vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sentence_vector(text, size,imdb_w2v):\n",
    "    \"\"\"\n",
    "    1、将每个 word 在 word2vec 模型中映射成为300维向量\n",
    "    2、句子的向量 = 每个word 的向量平均值\n",
    "    \"\"\"\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += imdb_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 word2vec 模型并生成词向量\n",
    "def get_train_vecs(x_train,x_test):\n",
    "    n_dim = 300\n",
    "    #初始化模型和词表\n",
    "    imdb_w2v = Word2Vec(size=n_dim, min_count=10)\n",
    "    imdb_w2v.build_vocab(x_train)\n",
    "    \n",
    "    #在评论训练集上建模(可能会花费几分钟)\n",
    "    imdb_w2v.train(x_train,total_examples=imdb_w2v.corpus_count, epochs=20)\n",
    "    \n",
    "    train_vecs = np.concatenate([build_sentence_vector(z, n_dim,imdb_w2v) for z in x_train])\n",
    "    #train_vecs = scale(train_vecs)\n",
    "    \n",
    "#     np.save('svm_data/train_vecs.npy',train_vecs)\n",
    "    print(train_vecs.shape)\n",
    "    #在测试集上训练\n",
    "    imdb_w2v.train(x_test,total_examples=imdb_w2v.corpus_count, epochs=20)\n",
    "    imdb_w2v.save('svm_data/w2v_model/w2v_model.pkl')\n",
    "    #Build test tweet vectors then scale\n",
    "    test_vecs = np.concatenate([build_sentence_vector(z, n_dim,imdb_w2v) for z in x_test])\n",
    "    #test_vecs = scale(test_vecs)\n",
    "#     np.save('svm_data/test_vecs.npy',test_vecs)\n",
    "    print(test_vecs.shape)\n",
    "    return train_vecs,test_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16884, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4221, 300)\n"
     ]
    }
   ],
   "source": [
    "train_vecs,test_vecs = get_train_vecs(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return train_vecs,y_train,test_vecs,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练svm模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train(train_vecs,y_train,test_vecs,y_test):\n",
    "    clf=SVC(kernel='rbf',verbose=True)\n",
    "    clf.fit(train_vecs,y_train)\n",
    "    joblib.dump(clf, 'svm_data/svm_model/model.pkl')\n",
    "    return clf.score(test_vecs,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]得分： 0.8654347311063729\n"
     ]
    }
   ],
   "source": [
    "# 计算模型性能\n",
    "score = svm_train(train_vecs,y_train,test_vecs,y_test)\n",
    "print(\"得分：\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建待预测句子的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_vecs(words):\n",
    "    n_dim = 300\n",
    "    imdb_w2v = Word2Vec.load('svm_data/w2v_model/w2v_model.pkl')\n",
    "    #imdb_w2v.train(words)\n",
    "    train_vecs = build_sentence_vector(words, n_dim,imdb_w2v)\n",
    "    #print train_vecs.shape\n",
    "    return train_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对单个句子进行情感判断 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(string):\n",
    "    words=jieba.lcut(string)\n",
    "    words_vecs=get_predict_vecs(words)\n",
    "    clf=joblib.load('svm_data/svm_model/model.pkl')\n",
    "     \n",
    "    result=clf.predict(words_vecs)\n",
    "    \n",
    "    if int(result[0])==1:\n",
    "        print(string,' positive')\n",
    "    else:\n",
    "        print (string,' negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "书脏了  negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "##对输入句子情感进行判断\n",
    "string='电池充完了电连手机都打不开.简直烂的要命.真是金玉其外,败絮其中!连5号电池都不如'\n",
    "string='书脏了'    \n",
    "svm_predict(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
