{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_dir='./wdl_data/model_save', model_type='deep', test_data='./wdl_data/adult.test', train_data='./wdl_data/adult.data', train_steps=2000)\n",
      "model directory = ./wdl_data/model_save\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014F86360A90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './wdl_data/model_save'}\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./wdl_data/model_save\\model.ckpt-2002\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dnn/binary_logistic_head/dnn/learning_rate not found in checkpoint\n\t [[node save/RestoreV2 (defined at d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1092)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"d:\\program\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\program\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\program\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\program\\python36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"d:\\program\\python36\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"d:\\program\\python36\\lib\\asyncio\\events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-fe02bfae12b6>\", line 258, in <module>\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-3-fe02bfae12b6>\", line 221, in main\n    FLAGS.train_data, FLAGS.test_data)\n  File \"<ipython-input-3-fe02bfae12b6>\", line 208, in train_and_eval\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 525, in fit\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1092, in _train_model\n    config=self._session_config) as mon_sess:\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 504, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 921, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 643, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1107, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1112, in _create_session\n    return self._sess_creator.create_session()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 800, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 557, in create_session\n    self._scaffold.finalize()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 215, in finalize\n    self._saver.build()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 789, in _build_internal\n    restore_sequentially, reshape)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 459, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1549, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dnn/binary_logistic_head/dnn/learning_rate not found in checkpoint\n\t [[node save/RestoreV2 (defined at d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1092)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key dnn/binary_logistic_head/dnn/learning_rate not found in checkpoint\n\t [[{{node save/RestoreV2}} = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1545\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1546\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1547\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key dnn/binary_logistic_head/dnn/learning_rate not found in checkpoint\n\t [[node save/RestoreV2 (defined at d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1092)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"d:\\program\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\program\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\program\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\program\\python36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"d:\\program\\python36\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"d:\\program\\python36\\lib\\asyncio\\events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-fe02bfae12b6>\", line 258, in <module>\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-3-fe02bfae12b6>\", line 221, in main\n    FLAGS.train_data, FLAGS.test_data)\n  File \"<ipython-input-3-fe02bfae12b6>\", line 208, in train_and_eval\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 525, in fit\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1092, in _train_model\n    config=self._session_config) as mon_sess:\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 504, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 921, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 643, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1107, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1112, in _create_session\n    return self._sess_creator.create_session()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 800, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 557, in create_session\n    self._scaffold.finalize()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 215, in finalize\n    self._saver.build()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 789, in _build_internal\n    restore_sequentially, reshape)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 459, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1549, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key dnn/binary_logistic_head/dnn/learning_rate not found in checkpoint\n\t [[node save/RestoreV2 (defined at d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1092)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1555\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1556\u001b[1;33m         \u001b[0mnames_to_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1557\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[1;34m(checkpoint_path)\u001b[0m\n\u001b[0;32m   1829\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[1;32m-> 1830\u001b[1;33m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[0;32m   1831\u001b[0m   object_graph_proto = (\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m    370\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[1;32m--> 371\u001b[1;33m                                           status)\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fe02bfae12b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fe02bfae12b6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     train_and_eval(FLAGS.model_dir, FLAGS.model_type, FLAGS.train_steps,\n\u001b[1;32m--> 221\u001b[1;33m                    FLAGS.train_data, FLAGS.test_data)\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fe02bfae12b6>\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[1;34m(model_dir, model_type, train_steps, train_data, test_data)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;31m# шонч╗Г\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[0;32m    523\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks)\u001b[0m\n\u001b[0;32m   1090\u001b[0m           \u001b[0msave_checkpoint_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Saving is handled by a hook.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m           \u001b[0msave_summaries_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m           config=self._session_config) as mon_sess:\n\u001b[0m\u001b[0;32m   1093\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[1;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[0;32m    502\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    919\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[0;32m    920\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    642\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \"\"\"\n\u001b[0;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    798\u001b[0m       \u001b[1;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       \u001b[1;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m       \u001b[1;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[1;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         config=config)\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[1;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;31m# Loads the checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecover_last_checkpoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_model_checkpoint_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1560\u001b[0m         \u001b[1;31m# a helpful message (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1561\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1562\u001b[1;33m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[0;32m   1563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m       \u001b[1;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dnn/binary_logistic_head/dnn/learning_rate not found in checkpoint\n\t [[node save/RestoreV2 (defined at d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1092)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"d:\\program\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\program\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\program\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\program\\python36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"d:\\program\\python36\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"d:\\program\\python36\\lib\\asyncio\\events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"d:\\program\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\program\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"d:\\program\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-fe02bfae12b6>\", line 258, in <module>\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-3-fe02bfae12b6>\", line 221, in main\n    FLAGS.train_data, FLAGS.test_data)\n  File \"<ipython-input-3-fe02bfae12b6>\", line 208, in train_and_eval\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 525, in fit\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1092, in _train_model\n    config=self._session_config) as mon_sess:\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 504, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 921, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 643, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1107, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1112, in _create_session\n    return self._sess_creator.create_session()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 800, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 557, in create_session\n    self._scaffold.finalize()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 215, in finalize\n    self._saver.build()\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 789, in _build_internal\n    restore_sequentially, reshape)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 459, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1549, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"d:\\program\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dnn/binary_logistic_head/dnn/learning_rate not found in checkpoint\n\t [[node save/RestoreV2 (defined at d:\\program\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1092)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Example code for TensorFlow Wide & Deep Tutorial using TF.Learn API.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# цХ░цНощЫЖчЪД Tag\n",
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "         \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "         \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "         \"income_bracket\"]\n",
    "LABEL_COLUMN = \"label\"\n",
    "# ч▒╗хИлхА╝\n",
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                     \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "# ш┐Юч╗нхА╝\n",
    "CONTINUOUS_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\",\n",
    "                    \"hours_per_week\"]\n",
    "\n",
    "\n",
    "def maybe_download(train_data, test_data):\n",
    "\n",
    "    \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "    if train_data:\n",
    "      train_file_name = train_data\n",
    "    else:\n",
    "      train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "      urllib.request.urlretrieve(\"http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data\", train_file.name)  # pylint: disable=line-too-long\n",
    "      train_file_name = train_file.name\n",
    "      train_file.close()\n",
    "      print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "    if test_data:\n",
    "      test_file_name = test_data\n",
    "    else:\n",
    "      test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "      urllib.request.urlretrieve(\"http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.test\", test_file.name)  # pylint: disable=line-too-long\n",
    "      test_file_name = test_file.name\n",
    "      test_file.close()\n",
    "      print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "    return train_file_name, test_file_name\n",
    "\n",
    "\n",
    "def build_estimator(model_dir, model_type):\n",
    "    \"\"\"Build an estimator.\"\"\"\n",
    "    # Sparse base columns.\n",
    "    # ч▒╗хИлч╝ЦчаБя╝Ъ text -> int\n",
    "    # gender цАзхИлхПкцЬЙ2ч▒╗я╝МчЫ┤цОе one-hot\n",
    "    gender = tf.contrib.layers.sparse_column_with_keys(column_name=\"gender\",\n",
    "                                                       keys=[\"female\", \"male\"])\n",
    "    # хп╣ф║Оч▒╗хИлш╛ГхдЪя╝МчЫ┤цОе hash \n",
    "    education = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "        \"education\", hash_bucket_size=1000)\n",
    "    relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "        \"relationship\", hash_bucket_size=100)\n",
    "    workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "        \"workclass\", hash_bucket_size=100)\n",
    "    occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "        \"occupation\", hash_bucket_size=1000)\n",
    "    native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "        \"native_country\", hash_bucket_size=1000)\n",
    "\n",
    "    # Continuous base columns.\n",
    "    # ш┐Юч╗нхА╝ч╝ЦчаБя╝ЪчЫ┤цОешО╖хПЦхА╝\n",
    "    age = tf.contrib.layers.real_valued_column(\"age\")\n",
    "    education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
    "    capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
    "    capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
    "    hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")\n",
    "\n",
    "    # Transformations.\n",
    "    # ф╜Ж х╣┤щ╛ДцШпхЕ│щФохнЧцо╡я╝Мф╕НхРМх╣┤щ╛Дцо╡хПпшГ╜хМЕхРлф╕НхРМцДПцАЭя╝МщЬАшжБчж╗цХгхМЦ\n",
    "    age_buckets = tf.contrib.layers.bucketized_column(age,\n",
    "                                                      boundaries=[\n",
    "                                                          18, 25, 30, 35, 40, 45,\n",
    "                                                          50, 55, 60, 65\n",
    "                                                      ])\n",
    "\n",
    "    # Wide columns and deep columns.\n",
    "    # ч║┐цАзцибхЮЛ чЙ╣х╛Б\n",
    "    # ф╕║ф╜Хф╕НчФиш┐Юч╗нхА╝чЙ╣х╛Бя╝Я\n",
    "    wide_columns = [gender, native_country, education, occupation, workclass,\n",
    "                    relationship, age_buckets,\n",
    "                    # чЙ╣х╛Бч╗ДхРИя╝ЪчмЫхНбхД┐чзп (цХЩшВ▓я╝МшБМф╕Ъ) ч╗ДцИРцЦ░чЪДчЙ╣х╛Б\n",
    "                    tf.contrib.layers.crossed_column([education, occupation],\n",
    "                                                     hash_bucket_size=int(1e4)),\n",
    "                    tf.contrib.layers.crossed_column(\n",
    "                        [age_buckets, education, occupation],\n",
    "                        hash_bucket_size=int(1e6)),\n",
    "                    tf.contrib.layers.crossed_column([native_country, occupation],\n",
    "                                                     hash_bucket_size=int(1e4))]\n",
    "    # DNN чЙ╣х╛Б хЕищГихПВцХ░я╝Мф╜Оч║мх║ж = хОЯхзЛчЙ╣х╛БхА╝я╝Мц▓бцЬЙч╗Пш┐ЗхдДчРЖ\n",
    "    # ш┐Юч╗нхА╝хПВцХ░цИЦцШп Embedding я╝МчеЮч╗Пч╜Сч╗ЬцЙНхе╜цДЯчЯе(цЬЙцДПф╣ЙчЪДхА╝)\n",
    "    deep_columns = [\n",
    "        tf.contrib.layers.embedding_column(workclass, dimension=8),\n",
    "        tf.contrib.layers.embedding_column(education, dimension=8),\n",
    "        tf.contrib.layers.embedding_column(gender, dimension=8),\n",
    "        tf.contrib.layers.embedding_column(relationship, dimension=8),\n",
    "        tf.contrib.layers.embedding_column(native_country,\n",
    "                                           dimension=8),\n",
    "        tf.contrib.layers.embedding_column(occupation, dimension=8),\n",
    "        age,\n",
    "        education_num,\n",
    "        capital_gain,\n",
    "        capital_loss,\n",
    "        hours_per_week,\n",
    "    ]\n",
    "\n",
    "    if model_type == \"wide\":\n",
    "      m = tf.contrib.learn.LinearClassifier(model_dir=model_dir,\n",
    "                                            feature_columns=wide_columns)\n",
    "    elif model_type == \"deep\":\n",
    "      m = tf.contrib.learn.DNNClassifier(model_dir=model_dir,\n",
    "                                         feature_columns=deep_columns,\n",
    "                                         hidden_units=[100, 50])\n",
    "    else:\n",
    "      m = tf.contrib.learn.DNNLinearCombinedClassifier(\n",
    "          model_dir=model_dir,\n",
    "          linear_feature_columns=wide_columns,\n",
    "          dnn_feature_columns=deep_columns,\n",
    "          dnn_hidden_units=[100, 50])\n",
    "    return m\n",
    "\n",
    "\n",
    "def input_fn(df):\n",
    "    \"\"\"Input builder function.\"\"\"\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored in a tf.SparseTensor.\n",
    "    categorical_cols = {\n",
    "        k: tf.SparseTensor(\n",
    "            indices=[[i, 0] for i in range(df[k].size)],\n",
    "            values=df[k].values,\n",
    "            dense_shape=[df[k].size, 1])\n",
    "        for k in CATEGORICAL_COLUMNS}\n",
    "    '''\n",
    "    categorical_cols = { \n",
    "        k: tf.SparseTensor( \n",
    "          indices=[[i, 0] for i in range(df[k].size)], \n",
    "          values=df[k].values,\n",
    "          shape=[df[k].size, 1]) \n",
    "        for k in CATEGORICAL_COLUMNS}    \n",
    "    '''\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(continuous_cols)\n",
    "    feature_cols.update(categorical_cols)\n",
    "    # Converts the label column into a constant Tensor.\n",
    "    label = tf.constant(df[LABEL_COLUMN].values)\n",
    "    # Returns the feature columns and the label.\n",
    "    return feature_cols, label\n",
    "\n",
    "\n",
    "def train_and_eval(model_dir, model_type, train_steps, train_data, test_data):\n",
    "    \"\"\"Train and evaluate the model.\"\"\"\n",
    "    # хЗЖхдЗцХ░цНощЫЖ\n",
    "    train_file_name, test_file_name = maybe_download(train_data, test_data)\n",
    "    df_train = pd.read_csv(\n",
    "        tf.gfile.Open(train_file_name),\n",
    "        names=COLUMNS,\n",
    "        skipinitialspace=True,\n",
    "        engine=\"python\")\n",
    "    df_test = pd.read_csv(\n",
    "        tf.gfile.Open(test_file_name),\n",
    "        names=COLUMNS,\n",
    "        skipinitialspace=True,\n",
    "        skiprows=1,\n",
    "        engine=\"python\")\n",
    "\n",
    "    # remove NaN elements\n",
    "    # хИащЩдцЬЙчй║хА╝чЪДцХ░цНо\n",
    "    df_train = df_train.dropna(how='any', axis=0)\n",
    "    df_test = df_test.dropna(how='any', axis=0)\n",
    "\n",
    "    # чФЯцИРцаЗчн╛ я╝М\">50K\" ф╕║1 хЕ╢ф╗Цф╕║0я╝Ыф║МхИЖч▒╗щЧощвШ\n",
    "    df_train[LABEL_COLUMN] = (\n",
    "        df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "    df_test[LABEL_COLUMN] = (\n",
    "        df_test[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "\n",
    "    model_dir = tempfile.mkdtemp() if not model_dir else model_dir\n",
    "    print(\"model directory = %s\" % model_dir)\n",
    "    # цибхЮЛ\n",
    "    m = build_estimator(model_dir, model_type)\n",
    "    # шонч╗Г\n",
    "    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\n",
    "    results = m.evaluate(input_fn=lambda: input_fn(df_test), steps=1)\n",
    "    for key in sorted(results):\n",
    "      print(\"%s: %s\" % (key, results[key]))\n",
    "    print(\"Train WDL End\")\n",
    "\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    print(FLAGS)\n",
    "    train_and_eval(FLAGS.model_dir, FLAGS.model_type, FLAGS.train_steps,\n",
    "                   FLAGS.train_data, FLAGS.test_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "    parser.add_argument(\n",
    "        \"--model_dir\",\n",
    "        type=str,\n",
    "        default=\"./wdl_data/model_save\",\n",
    "        help=\"Base directory for output models.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_type\",\n",
    "        type=str,\n",
    "        default=\"wide_n_deep\",\n",
    "        help=\"Valid model types: {'wide', 'deep', 'wide_n_deep'}.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_steps\",\n",
    "        type=int,\n",
    "        default=2000,\n",
    "        help=\"Number of training steps.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_data\",\n",
    "        type=str,\n",
    "        default=\"./wdl_data/adult.data\",\n",
    "        help=\"Path to the training data.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test_data\",\n",
    "        type=str,\n",
    "        default=\"./wdl_data/adult.test\",\n",
    "        help=\"Path to the test data.\"\n",
    "    )\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
